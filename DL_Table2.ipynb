{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iQxZ-Ykr9y1",
        "outputId": "70b4bdd7-4b92-4dec-a78c-815084ab4a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           filepaths           labels\n",
            "0  /content/drive/MyDrive/lung_colon_image_set/lu...  lung_image_sets\n",
            "1  /content/drive/MyDrive/lung_colon_image_set/lu...  lung_image_sets\n",
            "2  /content/drive/MyDrive/lung_colon_image_set/lu...  lung_image_sets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Function to load the dataset\n",
        "def load_dataset(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folders = os.listdir(data_dir)\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            filelist = os.listdir(folder_path)\n",
        "            for file in filelist:\n",
        "                fpath = os.path.join(folder_path, file)\n",
        "                filepaths.append(fpath)\n",
        "                labels.append(folder)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Load the dataset\n",
        "data_dir = '/content/drive/MyDrive/lung_colon_image_set'  # Update with your dataset path\n",
        "df = load_dataset(data_dir)\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s36tf12Dvyy",
        "outputId": "d4f604e9-88a9-4140-80a7-dcffc6f2e825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrXJC9_2sbz3",
        "outputId": "835d3b10-1b7e-40ff-9ec7-0e6b0327aeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n",
            " labels\n",
            "lung_image_sets    3\n",
            "Name: count, dtype: int64\n",
            "Training set size: (2, 2)\n",
            "Test set size: (1, 2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Part 1: Load the dataset\n",
        "def loading_the_data(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    classes = os.listdir(data_dir)\n",
        "    for cls in classes:\n",
        "        class_path = os.path.join(data_dir, cls)\n",
        "        if os.path.isdir(class_path):\n",
        "            for filename in os.listdir(class_path):\n",
        "                fpath = os.path.join(class_path, filename)\n",
        "                filepaths.append(fpath)\n",
        "                labels.append(cls)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Set your dataset path\n",
        "data_dir = '/content/drive/MyDrive/lung_colon_image_set'  # Update this path as necessary\n",
        "df = loading_the_data(data_dir)\n",
        "\n",
        "# Check class distribution\n",
        "class_counts = df['labels'].value_counts()\n",
        "print(\"Class distribution:\\n\", class_counts)\n",
        "\n",
        "# Determine a suitable test size\n",
        "# Calculate the number of instances to use for testing\n",
        "n_classes = df['labels'].nunique()\n",
        "max_test_size = min(class_counts.min(), 1)  # We can only take 1 instance from each class\n",
        "test_size = max_test_size * n_classes / len(df)  # Proportional test size\n",
        "\n",
        "# Part 2: Split the dataset into training and testing\n",
        "train_df, test_df = train_test_split(df, test_size=test_size, stratify=df['labels'], random_state=42)\n",
        "\n",
        "print(\"Training set size:\", train_df.shape)\n",
        "print(\"Test set size:\", test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcLIHCaC6y-H"
      },
      "source": [
        "activation function changed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UjD8wfNsifm",
        "outputId": "493c09b3-a36c-4da4-8380-c4f1a8550ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'lung_aca' has 5074 images.\n",
            "Class 'lung_n' has 5040 images.\n",
            "Class 'lung_scc' has 5051 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Specify the path to your folder containing the images\n",
        "folder_path = '/content/drive/MyDrive/lung_colon_image_set/lung_image_sets'\n",
        "\n",
        "# Get a list of all subdirectories (classes)\n",
        "classes = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n",
        "\n",
        "# Initialize a dictionary to store the count of images for each class\n",
        "class_counts = {}\n",
        "\n",
        "# Iterate over each class\n",
        "for cls in classes:\n",
        "    # Construct the full path to the class directory\n",
        "    class_path = os.path.join(folder_path, cls)\n",
        "    # Count the number of files in the class directory\n",
        "    num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
        "    # Store the count in the dictionary\n",
        "    class_counts[cls] = num_images\n",
        "\n",
        "# Print the count of images for each class\n",
        "for cls, count in class_counts.items():\n",
        "    print(f\"Class '{cls}' has {count} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lghwm9LeLeRo",
        "outputId": "428fe723-6549-469e-cccf-1f1a2d48e724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12132 validated image filenames belonging to 3 classes.\n",
            "Found 3033 validated image filenames belonging to 3 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5184s\u001b[0m 13s/step - accuracy: 0.8392 - loss: 0.4564 - val_accuracy: 0.9565 - val_loss: 0.1128\n",
            "Epoch 2/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 272ms/step - accuracy: 0.9590 - loss: 0.1124 - val_accuracy: 0.9542 - val_loss: 0.1490\n",
            "Epoch 3/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 272ms/step - accuracy: 0.9686 - loss: 0.0844 - val_accuracy: 0.9397 - val_loss: 0.1862\n",
            "Epoch 4/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 270ms/step - accuracy: 0.9799 - loss: 0.0515 - val_accuracy: 0.9664 - val_loss: 0.0892\n",
            "Epoch 5/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 334ms/step - accuracy: 0.9850 - loss: 0.0388 - val_accuracy: 0.9677 - val_loss: 0.1046\n",
            "Epoch 6/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 267ms/step - accuracy: 0.9888 - loss: 0.0354 - val_accuracy: 0.9690 - val_loss: 0.1186\n",
            "Epoch 7/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 279ms/step - accuracy: 0.9893 - loss: 0.0340 - val_accuracy: 0.9624 - val_loss: 0.1204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at: /content/drive/MyDrive/Model/inception.h5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 253ms/step\n",
            "Confusion Matrix:\n",
            "[[ 987    2   26]\n",
            " [   3 1005    0]\n",
            " [  71    0  939]]\n",
            "\n",
            "Classification Report:\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "         Lung_adenocarcinoma       0.93      0.97      0.95      1015\n",
            "          Lung_benign_tissue       1.00      1.00      1.00      1008\n",
            "Lung squamous_cell_carcinoma       0.97      0.93      0.95      1010\n",
            "\n",
            "                    accuracy                           0.97      3033\n",
            "                   macro avg       0.97      0.97      0.97      3033\n",
            "                weighted avg       0.97      0.97      0.97      3033\n",
            "\n",
            "\n",
            "Training data class counts:\n",
            "1: 4032\n",
            "0: 4059\n",
            "2: 4041\n",
            "\n",
            "Validation data class counts:\n",
            "0: 1015\n",
            "2: 1010\n",
            "1: 1008\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import Counter\n",
        "\n",
        "# Function to load data and preprocess\n",
        "def loading_the_data(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folders = os.listdir(data_dir)\n",
        "    for folder in folders:\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        if os.path.isdir(folder_path):  # Check if it's a directory\n",
        "            filelist = os.listdir(folder_path)\n",
        "            for file in filelist:\n",
        "                fpath = os.path.join(folder_path, file)\n",
        "                filepaths.append(fpath)\n",
        "                labels.append(folder)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Load the data\n",
        "data_dir = '/content/drive/MyDrive/lung_colon_image_set/lung_image_sets'\n",
        "df = loading_the_data(data_dir)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['labels'], random_state=42)\n",
        "\n",
        "# Image preprocessing and augmentation\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Load InceptionV3 model\n",
        "inceptionv3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "inceptionv3.trainable = False\n",
        "\n",
        "# Hybrid model architecture\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "inceptionv3_features = inceptionv3(inputs)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(inceptionv3_features)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n",
        "\n",
        "# Create the hybrid model\n",
        "hybrid_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "hybrid_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the hybrid model with early stopping\n",
        "history = hybrid_model.fit(train_generator, epochs=10, validation_data=validation_generator, callbacks=[early_stopping])\n",
        "\n",
        "# Save the model\n",
        "model_save_path = '/content/drive/MyDrive/Model/inception.h5'\n",
        "hybrid_model.save(model_save_path)\n",
        "print(\"Model saved at:\", model_save_path)\n",
        "\n",
        "# Predict classes for validation data\n",
        "val_preds = hybrid_model.predict(validation_generator)\n",
        "val_preds = np.argmax(val_preds, axis=1)\n",
        "\n",
        "# Get true labels for validation data\n",
        "true_labels = validation_generator.classes\n",
        "\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, val_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Display classification report\n",
        "class_names = ['Lung_adenocarcinoma', 'Lung_benign_tissue', 'Lung squamous_cell_carcinoma']\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, val_preds, target_names=class_names))\n",
        "\n",
        "# Count the occurrences of each class label in the training data\n",
        "train_class_counts = Counter(train_generator.classes)\n",
        "\n",
        "# Count the occurrences of each class label in the validation data\n",
        "val_class_counts = Counter(validation_generator.classes)\n",
        "\n",
        "# Print the number of images used for training and testing in each class\n",
        "print(\"\\nTraining data class counts:\")\n",
        "for class_name, count in train_class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")\n",
        "\n",
        "print(\"\\nValidation data class counts:\")\n",
        "for class_name, count in val_class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i1RBmYgcop7R",
        "outputId": "38d99000-0386-42ef-9d99-9adf98973630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12132 validated image filenames belonging to 3 classes.\n",
            "Found 1516 validated image filenames belonging to 3 classes.\n",
            "Found 1517 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_508 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_509 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_510 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_511 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,624</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_508 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_46 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_509 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_47 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_510 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_48 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_511 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_49 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │      \u001b[38;5;34m25,690,624\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,080,579</span> (99.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,080,579\u001b[0m (99.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,080,579</span> (99.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,080,579\u001b[0m (99.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 263ms/step - accuracy: 0.7654 - loss: 0.5826 - val_accuracy: 0.8832 - val_loss: 0.2585\n",
            "Epoch 2/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 246ms/step - accuracy: 0.9032 - loss: 0.2424 - val_accuracy: 0.9274 - val_loss: 0.1835\n",
            "Epoch 3/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 241ms/step - accuracy: 0.9183 - loss: 0.1968 - val_accuracy: 0.9380 - val_loss: 0.1578\n",
            "Epoch 4/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 241ms/step - accuracy: 0.9288 - loss: 0.1694 - val_accuracy: 0.9096 - val_loss: 0.2067\n",
            "Epoch 5/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 254ms/step - accuracy: 0.9471 - loss: 0.1382 - val_accuracy: 0.9551 - val_loss: 0.1260\n",
            "Epoch 6/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 243ms/step - accuracy: 0.9654 - loss: 0.0844 - val_accuracy: 0.9439 - val_loss: 0.1463\n",
            "Epoch 7/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 238ms/step - accuracy: 0.9712 - loss: 0.0722 - val_accuracy: 0.9730 - val_loss: 0.0745\n",
            "Epoch 8/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 246ms/step - accuracy: 0.9721 - loss: 0.0790 - val_accuracy: 0.9598 - val_loss: 0.1142\n",
            "Epoch 9/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 237ms/step - accuracy: 0.9812 - loss: 0.0513 - val_accuracy: 0.9650 - val_loss: 0.0839\n",
            "Epoch 10/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 241ms/step - accuracy: 0.9917 - loss: 0.0254 - val_accuracy: 0.9459 - val_loss: 0.1552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at: /content/drive/MyDrive/Model/yolo.h5/lung_cancer_detection_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 267ms/step - accuracy: 0.9600 - loss: 0.1062\n",
            "Test Loss: 0.14264294505119324\n",
            "Test Accuracy: 0.9545155167579651\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Function to load data and preprocess\n",
        "def loading_the_data(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folds = os.listdir(data_dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Change label names to its original names\n",
        "def change_label_names(df, column_name):\n",
        "    index = {'lung_aca': 'Lung_adenocarcinoma', 'lung_n': 'Lung_benign_tissue', 'lung_scc': 'Lung squamous_cell_carcinoma'}\n",
        "    df[column_name] = df[column_name].replace(index)\n",
        "\n",
        "# Load the data\n",
        "data_dir = '/content/drive/MyDrive/lung_colon_image_set/lung_image_sets'\n",
        "df = loading_the_data(data_dir)\n",
        "change_label_names(df, 'labels')\n",
        "\n",
        "# Split the dataset\n",
        "train_df, ts_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n",
        "valid_df, test_df = train_test_split(ts_df, train_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "# Image preprocessing and augmentation\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "valid_test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "valid_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    valid_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "def yolo_v2(input_shape=(224, 224, 3), num_classes=3):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Feature extraction layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Define the YOLOv2 model\n",
        "model = yolo_v2()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator\n",
        ")\n",
        "\n",
        "# Specify the folder path where you want to save the model\n",
        "model_save_folder = '/content/drive/MyDrive/Model/yolo.h5'\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = os.path.join(model_save_folder, \"lung_cancer_detection_model.h5\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "# Print the path where the model is saved\n",
        "print(\"Model saved at:\", model_save_path)\n",
        "\n",
        "# Whenever you want to test the model, load the saved model from the specific folder\n",
        "saved_model = load_model(model_save_path)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = saved_model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "ZMBmyGR_vUv_",
        "outputId": "ee62495b-f534-48cf-f871-c4a58cc58618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12132 validated image filenames belonging to 3 classes.\n",
            "Found 1516 validated image filenames belonging to 3 classes.\n",
            "Found 1517 validated image filenames belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,638,339</span> (93.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,638,339\u001b[0m (93.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,627</span> (4.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,050,627\u001b[0m (4.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3311s\u001b[0m 8s/step - accuracy: 0.4081 - loss: 1.1297 - val_accuracy: 0.5152 - val_loss: 0.9866\n",
            "Epoch 2/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 249ms/step - accuracy: 0.4935 - loss: 0.9977 - val_accuracy: 0.5607 - val_loss: 0.9077\n",
            "Epoch 3/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 246ms/step - accuracy: 0.5403 - loss: 0.9331 - val_accuracy: 0.6319 - val_loss: 0.8494\n",
            "Epoch 4/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 241ms/step - accuracy: 0.5868 - loss: 0.8627 - val_accuracy: 0.6926 - val_loss: 0.7460\n",
            "Epoch 5/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 245ms/step - accuracy: 0.6313 - loss: 0.7986 - val_accuracy: 0.6168 - val_loss: 0.8166\n",
            "Epoch 6/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 253ms/step - accuracy: 0.6292 - loss: 0.7941 - val_accuracy: 0.7546 - val_loss: 0.6780\n",
            "Epoch 7/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 244ms/step - accuracy: 0.6527 - loss: 0.7550 - val_accuracy: 0.7704 - val_loss: 0.6272\n",
            "Epoch 8/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 249ms/step - accuracy: 0.6670 - loss: 0.7242 - val_accuracy: 0.7533 - val_loss: 0.6244\n",
            "Epoch 9/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 247ms/step - accuracy: 0.6776 - loss: 0.6941 - val_accuracy: 0.7764 - val_loss: 0.5964\n",
            "Epoch 10/10\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 249ms/step - accuracy: 0.6859 - loss: 0.6712 - val_accuracy: 0.7856 - val_loss: 0.5581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at: /content/drive/MyDrive/Model/resNet.h5/lung_cancer_detection_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 7s/step - accuracy: 0.7825 - loss: 0.5643\n",
            "Test Loss: 0.550525426864624\n",
            "Test Accuracy: 0.7910349369049072\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Function to load data and preprocess\n",
        "def loading_the_data(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folds = os.listdir(data_dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Change label names to their original names\n",
        "def change_label_names(df, column_name):\n",
        "    index = {'lung_aca': 'Lung_adenocarcinoma', 'lung_n': 'Lung_benign_tissue', 'lung_scc': 'Lung squamous_cell_carcinoma'}\n",
        "    df[column_name] = df[column_name].replace(index)\n",
        "\n",
        "# Load the data\n",
        "data_dir = '/content/drive/MyDrive/lung_colon_image_set/lung_image_sets'\n",
        "df = loading_the_data(data_dir)\n",
        "change_label_names(df, 'labels')\n",
        "\n",
        "# Split the dataset\n",
        "train_df, ts_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n",
        "valid_df, test_df = train_test_split(ts_df, train_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "# Image preprocessing and augmentation\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "valid_test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "valid_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    valid_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Function to define ResNet-50 model\n",
        "def resnet_50(input_shape=(224, 224, 3), num_classes=3):\n",
        "    # Load the ResNet-50 model with pretrained weights from ImageNet, exclude top layers\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze the base model layers to not update during training\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom layers on top\n",
        "    inputs = Input(input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Define the ResNet-50 model\n",
        "model = resnet_50()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator\n",
        ")\n",
        "\n",
        "# Specify the folder path where you want to save the model\n",
        "model_save_folder = '/content/drive/MyDrive/Model/resNet.h5'\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = os.path.join(model_save_folder, \"lung_cancer_detection_resnet50_model.h5\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "# Print the path where the model is saved\n",
        "print(\"Model saved at:\", model_save_path)\n",
        "\n",
        "# Whenever you want to test the model, load the saved model from the specific folder\n",
        "saved_model = load_model(model_save_path)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = saved_model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFoBjoVZz-Iw",
        "outputId": "05d85a60-730a-4a68-d6ef-e79f78f52f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSH9KENPJWs3"
      },
      "source": [
        "**RESNET  50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "uYZu8cwhJZ24",
        "outputId": "2a4eced4-a773-4be1-81b4-fb10c3425551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4020 validated image filenames belonging to 3 classes.\n",
            "Found 502 validated image filenames belonging to 3 classes.\n",
            "Found 503 validated image filenames belonging to 3 classes.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,638,339</span> (93.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,638,339\u001b[0m (93.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,627</span> (4.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,050,627\u001b[0m (4.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 7s/step - accuracy: 0.4030 - loss: 1.1889 - val_accuracy: 0.5120 - val_loss: 1.0005\n",
            "Epoch 2/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m949s\u001b[0m 8s/step - accuracy: 0.4887 - loss: 1.0217 - val_accuracy: 0.5120 - val_loss: 0.9747\n",
            "Epoch 3/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m928s\u001b[0m 7s/step - accuracy: 0.5165 - loss: 0.9827 - val_accuracy: 0.5976 - val_loss: 0.9540\n",
            "Epoch 4/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 7s/step - accuracy: 0.5355 - loss: 0.9604 - val_accuracy: 0.5737 - val_loss: 0.9262\n",
            "Epoch 5/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 7s/step - accuracy: 0.5616 - loss: 0.9501 - val_accuracy: 0.5657 - val_loss: 0.8971\n",
            "Epoch 6/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m963s\u001b[0m 7s/step - accuracy: 0.5671 - loss: 0.9080 - val_accuracy: 0.5857 - val_loss: 0.8704\n",
            "Epoch 7/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 7s/step - accuracy: 0.5830 - loss: 0.8923 - val_accuracy: 0.6175 - val_loss: 0.8313\n",
            "Epoch 8/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 7s/step - accuracy: 0.5896 - loss: 0.8724 - val_accuracy: 0.6116 - val_loss: 0.8324\n",
            "Epoch 9/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 7s/step - accuracy: 0.6196 - loss: 0.8265 - val_accuracy: 0.6534 - val_loss: 0.7653\n",
            "Epoch 10/10\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m883s\u001b[0m 7s/step - accuracy: 0.6423 - loss: 0.7894 - val_accuracy: 0.7032 - val_loss: 0.7425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved at: /content/drive/MyDrive/Model/lung_cancer_detection_resnet50_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step - accuracy: 0.7122 - loss: 0.7531\n",
            "Test Loss: 0.7480602264404297\n",
            "Test Accuracy: 0.7137176990509033\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 6s/step\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "Lung squamous_cell_carcinoma       0.77      0.77      0.77       205\n",
            "         Lung_adenocarcinoma       0.61      0.41      0.49       161\n",
            "          Lung_benign_tissue       0.71      0.99      0.83       137\n",
            "\n",
            "                    accuracy                           0.71       503\n",
            "                   macro avg       0.70      0.72      0.70       503\n",
            "                weighted avg       0.70      0.71      0.70       503\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Function to load data and preprocess\n",
        "def loading_the_data(data_dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folds = os.listdir(data_dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "    df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Change label names to their original names\n",
        "def change_label_names(df, column_name):\n",
        "    index = {'lung_aca': 'Lung_adenocarcinoma', 'lung_n': 'Lung_benign_tissue', 'lung_scc': 'Lung squamous_cell_carcinoma'}\n",
        "    df[column_name] = df[column_name].replace(index)\n",
        "\n",
        "# Load the data\n",
        "data_dir = '/content/drive/MyDrive/lung_image_sets_1'\n",
        "df = loading_the_data(data_dir)\n",
        "change_label_names(df, 'labels')\n",
        "\n",
        "# Split the dataset\n",
        "train_df, ts_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\n",
        "valid_df, test_df = train_test_split(ts_df, train_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "# Image preprocessing and augmentation\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "valid_test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "valid_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    valid_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = valid_test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filepaths',\n",
        "    y_col='labels',\n",
        "    target_size=img_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Function to define ResNet-50 model\n",
        "def resnet_50(input_shape=(224, 224, 3), num_classes=3):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "    inputs = Input(input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Define the ResNet-50 model\n",
        "model = resnet_50()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator\n",
        ")\n",
        "\n",
        "# Specify the folder path where you want to save the model\n",
        "model_save_folder = '/content/drive/MyDrive/Model'\n",
        "model_save_path = os.path.join(model_save_folder, \"lung_cancer_detection_resnet50_model.h5\")\n",
        "model.save(model_save_path)\n",
        "\n",
        "# Print the path where the model is saved\n",
        "print(\"Model saved at:\", model_save_path)\n",
        "\n",
        "# Whenever you want to test the model, load the saved model from the specific folder\n",
        "saved_model = load_model(model_save_path)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = saved_model.evaluate(test_generator)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Get the true labels and predicted labels for the test set\n",
        "test_generator.reset()  # Reset the generator to ensure we get the right order\n",
        "predictions = saved_model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true classes from the test generator\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())  # Getting the labels for the classes\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}